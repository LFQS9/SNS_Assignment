{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "# Set seed for replayability\n",
    "from numpy.random import seed \n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family:\"Times New Roman\"'> <span styel=''>Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>newCasesByPublishDate</th>\n",
       "      <th>newDeaths28DaysByPublishDate</th>\n",
       "      <th>newAdmissions</th>\n",
       "      <th>hospitalCases</th>\n",
       "      <th>covidOccupiedMVBeds</th>\n",
       "      <th>London</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>4301</td>\n",
       "      <td>1224</td>\n",
       "      <td>1713</td>\n",
       "      <td>19139</td>\n",
       "      <td>3036</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>4451</td>\n",
       "      <td>847</td>\n",
       "      <td>1527</td>\n",
       "      <td>18533</td>\n",
       "      <td>2964</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>4583</td>\n",
       "      <td>682</td>\n",
       "      <td>1513</td>\n",
       "      <td>17867</td>\n",
       "      <td>2867</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>5386</td>\n",
       "      <td>1010</td>\n",
       "      <td>1525</td>\n",
       "      <td>17063</td>\n",
       "      <td>2703</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>4913</td>\n",
       "      <td>815</td>\n",
       "      <td>1255</td>\n",
       "      <td>16604</td>\n",
       "      <td>2702</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>18262</td>\n",
       "      <td>828</td>\n",
       "      <td>1880</td>\n",
       "      <td>26881</td>\n",
       "      <td>3373</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2021-02-07</td>\n",
       "      <td>15845</td>\n",
       "      <td>373</td>\n",
       "      <td>1846</td>\n",
       "      <td>26767</td>\n",
       "      <td>3302</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>14104</td>\n",
       "      <td>333</td>\n",
       "      <td>1909</td>\n",
       "      <td>26706</td>\n",
       "      <td>3230</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>12364</td>\n",
       "      <td>1052</td>\n",
       "      <td>1743</td>\n",
       "      <td>25643</td>\n",
       "      <td>3164</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>13013</td>\n",
       "      <td>1001</td>\n",
       "      <td>1715</td>\n",
       "      <td>24352</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  newCasesByPublishDate  newDeaths28DaysByPublishDate  \\\n",
       "0    2020-04-21                   4301                          1224   \n",
       "1    2020-04-22                   4451                           847   \n",
       "2    2020-04-23                   4583                           682   \n",
       "3    2020-04-24                   5386                          1010   \n",
       "4    2020-04-25                   4913                           815   \n",
       "..          ...                    ...                           ...   \n",
       "291  2021-02-06                  18262                           828   \n",
       "292  2021-02-07                  15845                           373   \n",
       "293  2021-02-08                  14104                           333   \n",
       "294  2021-02-09                  12364                          1052   \n",
       "295  2021-02-10                  13013                          1001   \n",
       "\n",
       "     newAdmissions  hospitalCases  covidOccupiedMVBeds  London  \n",
       "0             1713          19139                 3036    0.09  \n",
       "1             1527          18533                 2964    0.09  \n",
       "2             1513          17867                 2867    0.09  \n",
       "3             1525          17063                 2703    0.09  \n",
       "4             1255          16604                 2702    0.08  \n",
       "..             ...            ...                  ...     ...  \n",
       "291           1880          26881                 3373    0.21  \n",
       "292           1846          26767                 3302    0.21  \n",
       "293           1909          26706                 3230    0.24  \n",
       "294           1743          25643                 3164    0.22  \n",
       "295           1715          24352                 3132    0.22  \n",
       "\n",
       "[296 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('NewCases_Data/export_dataframe.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>newCasesByPublishDate</th>\n",
       "      <th>newDeaths28DaysByPublishDate</th>\n",
       "      <th>newAdmissions</th>\n",
       "      <th>hospitalCases</th>\n",
       "      <th>covidOccupiedMVBeds</th>\n",
       "      <th>London</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>4301</td>\n",
       "      <td>1224</td>\n",
       "      <td>1713</td>\n",
       "      <td>19139</td>\n",
       "      <td>3036</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>4451</td>\n",
       "      <td>847</td>\n",
       "      <td>1527</td>\n",
       "      <td>18533</td>\n",
       "      <td>2964</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>4583</td>\n",
       "      <td>682</td>\n",
       "      <td>1513</td>\n",
       "      <td>17867</td>\n",
       "      <td>2867</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>5386</td>\n",
       "      <td>1010</td>\n",
       "      <td>1525</td>\n",
       "      <td>17063</td>\n",
       "      <td>2703</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>4913</td>\n",
       "      <td>815</td>\n",
       "      <td>1255</td>\n",
       "      <td>16604</td>\n",
       "      <td>2702</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>18262</td>\n",
       "      <td>828</td>\n",
       "      <td>1880</td>\n",
       "      <td>26881</td>\n",
       "      <td>3373</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2021-02-07</td>\n",
       "      <td>15845</td>\n",
       "      <td>373</td>\n",
       "      <td>1846</td>\n",
       "      <td>26767</td>\n",
       "      <td>3302</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>14104</td>\n",
       "      <td>333</td>\n",
       "      <td>1909</td>\n",
       "      <td>26706</td>\n",
       "      <td>3230</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>12364</td>\n",
       "      <td>1052</td>\n",
       "      <td>1743</td>\n",
       "      <td>25643</td>\n",
       "      <td>3164</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>13013</td>\n",
       "      <td>1001</td>\n",
       "      <td>1715</td>\n",
       "      <td>24352</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  newCasesByPublishDate  newDeaths28DaysByPublishDate  \\\n",
       "0    2020-04-21                   4301                          1224   \n",
       "1    2020-04-22                   4451                           847   \n",
       "2    2020-04-23                   4583                           682   \n",
       "3    2020-04-24                   5386                          1010   \n",
       "4    2020-04-25                   4913                           815   \n",
       "..          ...                    ...                           ...   \n",
       "291  2021-02-06                  18262                           828   \n",
       "292  2021-02-07                  15845                           373   \n",
       "293  2021-02-08                  14104                           333   \n",
       "294  2021-02-09                  12364                          1052   \n",
       "295  2021-02-10                  13013                          1001   \n",
       "\n",
       "     newAdmissions  hospitalCases  covidOccupiedMVBeds  London  \n",
       "0             1713          19139                 3036    0.09  \n",
       "1             1527          18533                 2964    0.09  \n",
       "2             1513          17867                 2867    0.09  \n",
       "3             1525          17063                 2703    0.09  \n",
       "4             1255          16604                 2702    0.08  \n",
       "..             ...            ...                  ...     ...  \n",
       "291           1880          26881                 3373    0.21  \n",
       "292           1846          26767                 3302    0.21  \n",
       "293           1909          26706                 3230    0.24  \n",
       "294           1743          25643                 3164    0.22  \n",
       "295           1715          24352                 3132    0.22  \n",
       "\n",
       "[296 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df[['date','newCasesByPublishDate','newDeaths28DaysByPublishDate'\n",
    "             ,'newAdmissions','hospitalCases','covidOccupiedMVBeds','London']]\n",
    "df_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (222, 6)\n",
      "test set: (74, 6)\n"
     ]
    }
   ],
   "source": [
    "# Separate dates for future plotting\n",
    "all_dates = pd.to_datetime(df_data['date'])\n",
    "\n",
    "# Extract features\n",
    "n_features = 6\n",
    "cols = list(df_data)[1:n_features + 1]\n",
    "data = df_data[cols].astype(float)\n",
    "\n",
    "# Split into the train set and the test set\n",
    "split = 0.75\n",
    "x = int(data.shape[0] * split)\n",
    "train_set, test_set = data[:x], data[x:]\n",
    "print(\"train set:\", train_set.shape)\n",
    "print(\"test set:\", test_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: (222, 6)\n",
      "train set type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Number of days predicted into the future\n",
    "n_future = 5\n",
    "\n",
    "# Number of past days used as the input\n",
    "n_past = 4\n",
    "\n",
    "# Normalize the train set\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(train_set)\n",
    "train_data_scaled = scaler.transform(train_set)\n",
    "\n",
    "print(\"train set size:\", train_data_scaled.shape)\n",
    "print(\"train set type:\", type(train_data_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x: (214, 4, 6)\n",
      "train y: (214, 5)\n"
     ]
    }
   ],
   "source": [
    "# Reshape input and output\n",
    "train_X, train_Y = [], []\n",
    "\n",
    "for i in range(n_past, train_data_scaled.shape[0] - n_future + 1):\n",
    "    train_X.append(train_data_scaled[i - n_past:i, 0:train_data_scaled.shape[1]])\n",
    "    train_Y.append(train_data_scaled[i:i + n_future, 0])\n",
    "\n",
    "train_x, train_y = np.array(train_X), np.array(train_Y)\n",
    "\n",
    "print(\"train x:\", train_x.shape)\n",
    "print(\"train y:\", train_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family:\"Times New Roman\"'> <span styel=''>Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.4318 - val_loss: 0.4606\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.3306\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.2115\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.1265\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0815\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0717\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0777\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0761\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0713\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0686\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0733\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0703\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0694\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0711\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0710\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0751\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0741\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0702\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0715\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0710\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0701\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0697\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0698\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0697\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0697\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0698\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0697\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0699\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0700\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0700\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0700\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0700\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0700\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0699\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0699\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0699\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0699\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0699\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0699\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0699\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0699\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0699\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0699\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0699\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0699\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0699\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0699\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0699\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0699\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0699\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0699\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0699\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0699\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0699\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0699\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0699\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0699\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0699\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0699\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0699\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0699\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0699\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0699\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0699\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0699\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0699\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0699\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0699\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0699\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0699\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0699\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0699\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0699\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0699\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0699\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0699\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0699\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0699\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0699\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0699\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0699\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0699\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0699\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0699\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0699\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0699\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0699\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0699\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0699\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0699\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0699\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0699\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0699\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0699\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0699\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0699\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0699\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0699\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0699\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0699\n"
     ]
    }
   ],
   "source": [
    "# CNN-Bi-LSTM model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(32, activation='relu', return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(32, activation='relu')))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(train_y.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Training\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, mode='auto')\n",
    "history = model.fit(train_x, train_y, epochs=100, batch_size=n_past, validation_split=0.1, verbose=1, callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family:\"Times New Roman\"'> <span styel=''>Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'model train vs validation loss')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot model train vs validation loss\n",
    "sns.lineplot(data=history.history['loss'])\n",
    "sns.lineplot(data=history.history['val_loss'])\n",
    "plt.legend(labels=['train', 'validation'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"model train vs validation loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family:\"Times New Roman\"'> <span styel=''>Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test x shape: (66, 4, 6)\n",
      "test y shape: (66, 5)\n"
     ]
    }
   ],
   "source": [
    "# Reshape input and output\n",
    "test_data_scaled = scaler.transform(test_set)\n",
    "\n",
    "test_X, test_Y = [], []\n",
    "\n",
    "for i in range(n_past, test_data_scaled.shape[0] - n_future + 1):\n",
    "    test_X.append(test_data_scaled[i - n_past:i, 0:test_data_scaled.shape[1]])\n",
    "    test_Y.append(test_data_scaled[i:i + n_future, 0])\n",
    "\n",
    "test_x, test_y = np.array(test_X), np.array(test_Y)\n",
    "\n",
    "print(\"test x shape:\", test_x.shape)\n",
    "print(\"test y shape:\", test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7871\n",
      "validation:\n",
      "Day-1 RMSE is 4159.358087\n",
      "Day-2 RMSE is 4191.879968\n",
      "Day-3 RMSE is 4311.129533\n",
      "Day-4 RMSE is 4569.762185\n",
      "Day-5 RMSE is 4639.611445\n",
      "****************************************\n",
      "test:\n",
      "Day-1 RMSE is 14535.721945\n",
      "Day-2 RMSE is 14515.322382\n",
      "Day-3 RMSE is 14333.801849\n",
      "Day-4 RMSE is 14795.376090\n",
      "Day-5 RMSE is 15275.825152\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_y)\n",
    "predict_y = model.predict(test_x)\n",
    "model_y = model.predict(train_x)\n",
    "\n",
    "\n",
    "# Inverse transform for multiple output\n",
    "def inverse_transform(data):\n",
    "    for i in range(len(data)):\n",
    "        data_copies = data[i]\n",
    "        data_copies = np.repeat(data_copies[:, np.newaxis], train_set.shape[1], 1)\n",
    "        data[i] = scaler.inverse_transform(data_copies)[:, 0]\n",
    "    return data\n",
    "\n",
    "\n",
    "predict_y = inverse_transform(predict_y)\n",
    "test_y = inverse_transform(test_y)\n",
    "model_y = inverse_transform(model_y)\n",
    "train_y = inverse_transform(train_y)\n",
    "\n",
    "\n",
    "# Evaluate per-day predictions\n",
    "def perDay_rmse(tests, predictions):\n",
    "    for i in range(n_future):\n",
    "        actual = [test[i] for test in tests]\n",
    "        predicted = [prediction[i] for prediction in predictions]\n",
    "        rmse = mean_squared_error(actual, predicted, squared=False)\n",
    "        print('Day-%d RMSE is %f' % ((i + 1), rmse))\n",
    "\n",
    "\n",
    "print(\"validation:\")\n",
    "perDay_rmse(train_y[int(-0.1 * len(train_x)) - 1:], model_y[int(-0.1 * len(train_x)) - 1:])\n",
    "\n",
    "print(\"*\"*40)\n",
    "print(\"test:\")\n",
    "perDay_rmse(test_y, predict_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
